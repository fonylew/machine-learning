{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Objective: To see how well each classification algorithm performs on rule inductions and compare model complexities between models"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom matplotlib.colors import ListedColormap",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "cell_type": "code",
   "source": "# [For Kaggle only]\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "trusted": true
   },
   "cell_type": "code",
   "source": "data_path = '../input/poker-rule-induction/'\n\ntrain_data = pd.read_csv(data_path + 'train.csv.zip')\ntest_data = pd.read_csv(data_path + 'test.csv.zip')\n\ndf = train_data\ndf.head()",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/poker-rule-induction/train.csv.zip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-dc9ae2770390>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mdata_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'../input/poker-rule-induction/'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mtrain_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'train.csv.zip'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mtest_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'test.csv.zip'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    684\u001B[0m     )\n\u001B[1;32m    685\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 686\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    451\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 452\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    453\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    454\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    934\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 936\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    937\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    938\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1166\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1167\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1168\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1169\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1170\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   1996\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1997\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1998\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1999\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2000\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml/lib/python3.7/zipfile.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001B[0m\n\u001B[1;32m   1238\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1239\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1240\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilemode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1241\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1242\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mfilemode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodeDict\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../input/poker-rule-induction/train.csv.zip'"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Poker Hand dataset\n\nDataset Link: https://archive.ics.uci.edu/ml/datasets/Poker+Hand\n(Description below is from the dataset link)\n\n**Creators:**\n\nRobert Cattral (cattral '@' gmail.com)\n\nFranz Oppacher (oppacher '@' scs.carleton.ca)\nCarleton University, Department of Computer Science\nIntelligent Systems Research Unit\n1125 Colonel By Drive, Ottawa, Ontario, Canada, K1S5B6\n\n**Data Set Information:**\n\nEach record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. There is one Class attribute that describes the \"Poker Hand\". The order of cards is important, which is why there are 480 possible Royal Flush hands as compared to 4 (one for each suit - explained in [Web Link]).\n\n**Attribute Information:**\n\n1) S1 \"Suit of card #1\"\nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n2) C1 \"Rank of card #1\"\nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n3) S2 \"Suit of card #2\"\nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n4) C2 \"Rank of card #2\"\nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n5) S3 \"Suit of card #3\"\nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n6) C3 \"Rank of card #3\"\nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n7) S4 \"Suit of card #4\"\nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n8) C4 \"Rank of card #4\"\nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n9) S5 \"Suit of card #5\"\nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n10) C5 \"Rank of card 5\"\nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n11) hand CLASS \"Poker Hand\"\nOrdinal (0-9)\n\n- 0: Nothing in hand; not a recognized poker hand\n- 1: One pair; one pair of equal ranks within five cards\n- 2: Two pairs; two pairs of equal ranks within five cards\n- 3: Three of a kind; three equal ranks within five cards\n- 4: Straight; five cards, sequentially ranked with no gaps\n- 5: Flush; five cards with the same suit\n- 6: Full house; pair + different rank three of a kind\n- 7: Four of a kind; four equal ranks within five cards\n- 8: Straight flush; straight + flush\n- 9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush "
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dimension"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "print(\"Train data shape: \",train_data.shape)\nprint(\"Test data shape: \",test_data.shape)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Quality Check"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# check on DataFrame basic information\ndf.info()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "no any missing value"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# check unique value in each column\ndf.hand.nunique()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All attributes contain all possible values"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# check duplication\ndf.duplicated().groupby()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EDA"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "color = cm.CMRmap(np.linspace(0.1, 0.8, df.hand.nunique()))\nax = df.groupby('hand').count()[['S1']].plot(kind='bar', color=color)\nax.set_title(\"No. of instances per class\")\nax.set_ylabel(\"No. of class\")\nax.set_xlabel(\"Classes\")\nplt.grid()\n\ndf.groupby('hand').count()[['S1']]",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "df.columns",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Experiment "
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nh = .02  # step size in the mesh\n\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1, max_iter=1000),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]\n\n# X, y = make_classification(n_features=10, n_redundant=0, n_informative=10,\n#                            random_state=1, n_clusters_per_class=1)\n# rng = np.random.RandomState(2)\n# X += 2 * rng.uniform(size=X.shape)\n# linearly_separable = (X, y)\n\n# datasets = train_data\n\n# figure = plt.figure(figsize=(27, 9))\n# i = 1\n\n# preprocess dataset, split into training and test part\nX_train, y_train = train_data[['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5']], train_data[['hand']]\nX_test, y_test = test_data[['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5']], test_data[['hand']]\n# X = StandardScaler().fit_transform(X)\n# X_train, X_test, y_train, y_test = \\\n#     train_test_split(X, y, test_size=.4, random_state=42)\n\n# x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n# y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n#                      np.arange(y_min, y_max, h))\n\n# just plot the dataset first\n# cm = plt.cm.RdBu\n# cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n# ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n# if ds_cnt == 0:\n#     ax.set_title(\"Input data\")\n# Plot the training points\n# ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n#            edgecolors='k')\n# Plot the testing points\n# ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n#            edgecolors='k')\n# ax.set_xlim(xx.min(), xx.max())\n# ax.set_ylim(yy.min(), yy.max())\n# ax.set_xticks(())\n# ax.set_yticks(())\n# i += 1\n\n# iterate over classifiers\nfor name, clf in zip(names, classifiers):\n#     ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n    clf.fit(X_train, y_train)\n    score = clf.score(X_test, y_test)\n    print(names, score)\n    # Plot the decision boundary. For that, we will assign a color to each\n    # point in the mesh [x_min, x_max]x[y_min, y_max].\n#     if hasattr(clf, \"decision_function\"):\n#         Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n#     else:\n#         Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n\n    # Put the result into a color plot\n#     Z = Z.reshape(xx.shape)\n#     ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n\n    # Plot the training points\n#     ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n#                edgecolors='k')\n    # Plot the testing points\n#     ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n#                edgecolors='k', alpha=0.6)\n\n#     ax.set_xlim(xx.min(), xx.max())\n#     ax.set_ylim(yy.min(), yy.max())\n#     ax.set_xticks(())\n#     ax.set_yticks(())\n#     if ds_cnt == 0:\n#         ax.set_title(name)\n#     ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n#             size=15, horizontalalignment='right')\n#     i += 1\n\n# plt.tight_layout()\n# plt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 Decision Trees\nwith some form of pruning and describe split attributes"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 Neural Networks\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 Boosting\nwith much more aggressive about pruning"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4 Support Vector Machines\nwith at least two kernel functions"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5 K-Nearest Neighbors\nwith different values of k"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# References\n- https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7ba83a6e",
   "language": "python",
   "display_name": "PyCharm (machine-learning)"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}